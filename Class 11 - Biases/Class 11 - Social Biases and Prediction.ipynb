{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33bd506a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <div align=\"center\"> SPECIAL TOPICS III </div>\n",
    "## <div align=\"center\"> Data Science for Social Scientists  </div>\n",
    "### <div align=\"center\"> ECO 4199 </div>\n",
    "#### <div align=\"center\">Class 11 - Social Biases and Prediction</div>\n",
    "<div align=\"center\"> Jonathan Holmes, (he/him)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b47bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Brief Review \n",
    "\n",
    "$$y = f(x) + \\varepsilon$$\n",
    "\n",
    "Machine learning is: \n",
    "1. Different functions that approximate $f(x)$\n",
    "2. Methods to estimate $\\hat{f}(x)$ \n",
    "3. Measures to identify how close $\\hat{f}$ got to the ``true'' $f$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0f860",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning Methods in One Expression\n",
    "\n",
    "$$\\min \\underbrace{\\sum_{i=1}^n L(f(x_i), y_i)}_{\\text{in-sample loss}} \n",
    "     + \\underbrace{\\lambda \\sum_{k=1}^k P(\\beta_k)}_{\\text{complexity restriction}}$$\n",
    "     \n",
    "Equivalently (for the mathematically inclined): \n",
    "\n",
    "$$\\min \\underbrace{\\sum_{i=1}^n L(f(x_i), y_i)}_{\\text{in-sample loss}} \\text{ over } \\underbrace{f \\in F}_{\\text{function class}} \\text{ subject to } \\underbrace{R(f) \\leq c}_{\\text{complexity restriction}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e142a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning Methods in One Expression\n",
    "\n",
    "$$\\min \\underbrace{\\sum_{i=1}^n L(f(x_i), y_i)}_{\\text{in-sample loss}} \n",
    "     + \\underbrace{\\lambda \\sum_{k=1}^k P(\\beta_k)}_{\\text{complexity restriction}}$$\n",
    "\n",
    "### The choice of functions $f$ \n",
    "- Linear models ($f(X) = \\beta_0 + \\beta_1 X_1 + ... + \\beta_N X_N$)\n",
    "- Logistic models\n",
    "- Neural networks\n",
    "\n",
    "Other models we have not learned in depth \n",
    "- Tree models\n",
    "- Random forest\n",
    "- K-nearest neighbour\n",
    "- Suppor vector machines\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f542f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning Methods in One Expression\n",
    "$$\\min \\underbrace{\\sum_{i=1}^n L(f(x_i), y_i)}_{\\text{in-sample loss}} \n",
    "     + \\underbrace{\\lambda \\sum_{k=1}^k P(\\beta_k)}_{\\text{complexity restriction}}$$\n",
    "\n",
    "\n",
    "### The set of loss functions\n",
    "- Mean-squared error $L(\\hat{f}(x_i), y_i) = \\frac{1}{n} \\sum_{i=1}^N (\\hat{f}(x_i) - y_i)^2$\n",
    "- Mean absolute error $L(\\hat{f}(x_i), y_i) = \\frac{1}{n} \\sum_{i=1}^N |\\hat{f}(x_i) - y_i|$\n",
    "\n",
    "Other functions we have not learned: \n",
    "- Log Loss\n",
    "- Huber Loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df54bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning Methods in One Expression\n",
    "$$\\min \\underbrace{\\sum_{i=1}^n L(f(x_i), y_i)}_{\\text{in-sample loss}} \n",
    "     + \\underbrace{\\lambda \\sum_{k=1}^k P(\\beta_k)}_{\\text{regularization}}$$\n",
    "     \n",
    "Complexity restriction: \n",
    "1. Nothing (OLS, basic neural networks, etc.)\n",
    "2. Lasso: $P(\\beta_k) = |\\beta_k|$\n",
    "3. Ridge: $P(\\beta_k) = (\\beta_k)^2$\n",
    "\n",
    "We call these restrictions __REGULARIZATION__\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71447541",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mix-and-match\n",
    "\n",
    "$$\\min \\underbrace{\\sum_{i=1}^n L(f(x_i), y_i)}_{\\text{in-sample loss}} \n",
    "     + \\underbrace{\\lambda \\sum_{k=1}^k P(\\beta_k)}_{\\text{regularization}}$$\n",
    "\n",
    "\n",
    "We have learned this is ok: \n",
    "- Linear regression + Lasso Regularization = Lasso Regression\n",
    "\n",
    "But you can also mix-and-match: \n",
    "- Neural network + Lasso regularization \n",
    "- Logistic regression + Ridge regularization\n",
    "- Etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb015a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy of the model\n",
    "\n",
    "Measures: \n",
    "- Core methods: Mean-squared error, mean absolute error\n",
    "- We have not seen: Log loss, Huber loss, etc\n",
    "- Corrected statistics: Adjusted $R^2$, AIC, BIC\n",
    "- Cross-validation\n",
    "\n",
    "Again, you can uses any of these statistics depending on your needs! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74429d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Function Classes\n",
    "- Recall that there is no one function class that is better over all predictive tasks all the time\n",
    "- If you want to know which performs best a good way would to try them all at once\n",
    "- It turns out that [PyCaret](https://pycaret.org/) can do this for you\n",
    "- I will briefly cover their [tutorial](https://github.com/pycaret/pycaret/tree/master/tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4517770c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concerns About Machine Learning\n",
    "\n",
    "Examples: \n",
    "- Deepfakes, disinformation, spam \n",
    "- Re-creating art: \n",
    "    - Less jobs/career prospects for some industries\n",
    "    - What will happen to the economy? \n",
    "    - Plagiarism? \n",
    "- Algorithms running amok (self-driving car cashes?)\n",
    "    - Who is legally responsible when a self-driving car crashes? \n",
    "- Biased models! (Racism, sexism, etc)\n",
    "    - The model reflects the data, easy to exclude some ideas/populations/etc. \n",
    "- AI Singularity, AIs taking over \n",
    "- We don't understand why AIs do what they do, unintended consequences? \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974ae92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concerns About Machine Learning\n",
    "\n",
    "1. ML models can be _biased_ (algorithmic bias)\n",
    "2. We may not understant why ML models do what they do. \n",
    "3. We may lose control of machine learning models (robot takeover)\n",
    "4. ML will replace humans (loss of jobs)\n",
    "5. ML may centralize economic power in a small number of companies\n",
    "6. ML models copy the work of people who are uncompensated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642eb939",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This class: ML and data-induced biases\n",
    "\n",
    "1. Sample-induced bias\n",
    "2. Machines replicating society's bias\n",
    "3. Incomplete feature sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508ab82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://4.img-dpreview.com/files/p/E~TS590x0~articles/4871415337/googlebrain.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88c434",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ML and Upsampling\n",
    "- The way to do this is beyond the scope of this lecture\n",
    "- But the method isn't very different from what we have learned\n",
    "- The upsampling in the previous example takes a matrix X of dimension 8x8\n",
    "- It outputs a matrix Y of dimension 32x32\n",
    "$$\\mathbf{Y} = f(\\mathbf{X})$$\n",
    "- For every pixel, the function output 4 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792723e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ML training\n",
    "- So a deep learning neural network was trained to predict higher resolution picture\n",
    "- The way to do this is of course to feed the NN a low resolution picture and use the high resolution picture as a target\n",
    "- The NN learns from this data the pixels it should output given a low resolution picture\n",
    "- How good this network is determined by how close it gets to the data it received"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e2784",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Who is this guy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b84f52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](obama.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7730f61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ML test\n",
    "- As should be clear by now, ML algorithms are only as good as their prediction out of sample\n",
    "- Seeing the picture from the previous slide it is obvious to us that this low resolution picture represents Obama\n",
    "- We are therefore able to reconstruct the image based on our recollection of Obama's features\n",
    "- Not the trained NN, it is only able to output a new matrix Y, based on the weights that best fitted the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f2041",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://cdn.vox-cdn.com/thumbor/MXX-mZqWLQZW8Fdx1ilcFEHR8Wk=/55x85:768x536/1820x1213/filters:focal(336x236:464x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/66972412/face_depixelizer_obama.0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0656b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ML and out of sample prediction\n",
    "- Did the algorithm fail?\n",
    "- If you were presented with the right picture only and knew this was generated by a computer you would probably be very impressed\n",
    "- When compared to the left picture this is outrageously wrong\n",
    "- But is it enough to talk about biases?\n",
    "- Here are a few other out of sample predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090ff50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://pbs.twimg.com/media/Ea-8T2NXkAEfH6y?format=png&name=900x900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1874ebb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://pbs.twimg.com/media/Ea_AGceXYAYg4KT?format=jpg&name=medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d01fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample induced bias\n",
    "- The model has learned to mimic the data on which it is based\n",
    "- If training data is full of white faces, then the model will re-create white faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3241b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Solution: \n",
    "- Train the dataset on a sample that is _representative_ of the population at large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64d868",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Biased Training Data -> Biased Models\n",
    "- Amazon used ML to select good resumes\n",
    "- Data: Past people hired and not hired\n",
    "- Algorithm: Predict who was hired based on resume\n",
    "- Problem: Most past hires were white men\n",
    "\n",
    "Result: Model gave higher grades to white men"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83329777",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Biased Training Data -> Biased Models\n",
    "- A health insurance company wants to identify sickest patients to give them access to a new program\n",
    "- Data: Past health insurance patients\n",
    "- Algorithm: Predict who had high health costs (as a proxy for patient health)\n",
    "- Problem: Black patients historically had lower spending, and were less likely to be diagnosed with health conditions\n",
    "\n",
    "Result: Model selected mostly non-black patients for the new program\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58319c94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Biased Training Data -> Biased Models\n",
    "\n",
    "- Chatbots are trained on massive datasets of text from the internet\n",
    "- Problem: Many internet posts are: \n",
    "    - Biased towards specific groups (racist, sexist, etc.)\n",
    "    - Rude, insulting, or similar\n",
    "\n",
    "Result: Chatbots can also be racist/sexist/rude, etc. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae628f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Biased Training Data -> Biased Models\n",
    "- The model learns to mimic the data on which it is based. \n",
    "\n",
    "\n",
    "### Solutions: \n",
    "- This is a hard problem! \n",
    "- Can remove biased training data (if possible)\n",
    "- Can sensor biased output (eg: ChatGPT) \n",
    "- Can analyze predictions to test for bias; tweak biased models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773f616",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case study: Recitivism in the U.S. \n",
    "- Many states in the US are now using Machine Learning to predict how a defendantâ€™s risk of future crime\n",
    "- The goal is to remove the judge bias and try to predict \"objectively\" based on some data who was likely to comit a crime again in the future\n",
    "- A classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e037f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example continued\n",
    "- When performing classification tasks, one can use a confusion matrix\n",
    "\n",
    "|Prediction/Reality| FALSE | TRUE |\n",
    "| ---| --- | --- |\n",
    "|__FALSE__| True Negative | False Negative | \n",
    "|__TRUE__| False Positive | True Positive | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbaa8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example continued\n",
    "- An important [research project](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) looked at the algorithm created by the for-profit company: Northpointe.\n",
    "    - The formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\n",
    "    - White defendants were mislabeled as low risk more often than black defendants.\n",
    "    - The algorithm was somewhat more accurate than a coin flip. Of those deemed likely to re-offend, 61 percent were arrested for any subsequent crimes within two years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f891fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example continued\n",
    "\n",
    "Note: Race was not a variable used in the Northpointe analysis. \n",
    "\n",
    "- Many underlying variables can be correlated with race! \n",
    "- It can be possible that the machine can use other factors correlated with race to predict recidivism\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c7956",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Eliminating bias in ML models\n",
    "\n",
    "Area of current research: \n",
    "- Econometrics + Machine Learning: Combined approaches combining causal and predictive analysis\n",
    "- Researchers providing guidance ([example](https://www.chicagobooth.edu/-/media/project/chicago-booth/centers/caai/docs/algorithmic-bias-playbook-june-2021) )\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
